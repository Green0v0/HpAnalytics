{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit_metrics_print(model, X_train, y_train, X_val, y_val):\n",
    "#     from sklearn.metrics import accuracy_score, classification_report\n",
    "#     model.fit(X_train, y_train)\n",
    "    \n",
    "#     pred_train = model.predict(X_train)\n",
    "#     pred_val = model.predict(X_val)\n",
    "#     print(model)\n",
    "#     print()\n",
    "#     print('train accuracy :', accuracy_score(y_train, pred_train))\n",
    "#     print('validation accuracy :', accuracy_score(y_val, pred_val))\n",
    "#     print('='*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('../data/ohe_edit_4.8.1(add_col).csv')\n",
    "X.drop(columns='target', inplace=True)\n",
    "y = pd.read_csv('../data/ohe_edit_4.8.1(add_col).csv')['target']\n",
    "X_test = pd.read_csv('../data/prepcd_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 우상님 코드용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.rename(columns={'company_size_<10':'company_size_~10'},inplace=True)\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, shuffle=True, random_state=1)\n",
    "# X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 내코드용 1차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pd.read_csv('../data/prepcd_train.csv')\n",
    "# X.drop(columns='target', inplace=True)\n",
    "# y = pd.read_csv('../data/prepcd_train.csv')['target']\n",
    "# X_test = pd.read_csv('../data/prepcd_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 내코드용 2차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('../data/prepcd_lbe_train.csv')\n",
    "X.drop(columns='target', inplace=True)\n",
    "y = pd.read_csv('../data/prepcd_lbe_train.csv')['target']\n",
    "X_test = pd.read_csv('../data/prepcd_lbe_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14368, 13), (4790, 13), (14368,), (4790,))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, shuffle=True, random_state=1)\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial 컬럼 추가(Trial&Error) XGBoost모델 feature_importances_ 기준"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중요도 컬럼뽑기 - 랜덤서치(nopoly,no oversampling) 한번 실행후"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['city_development_index', 'company_size', 'education_level']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imprt_lst = pd.Series(be.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "to_poly_lst = list(imprt_lst[imprt_lst>imprt_lst.quantile(q=0.8)].index)\n",
    "to_poly_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_f = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly_f1 = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "poly_train = poly_f.fit_transform(X.loc[:,X.columns.isin(to_poly_lst)])\n",
    "poly_test = poly_f1.fit_transform(X_test.loc[:,X_test.columns.isin(to_poly_lst)])\n",
    "\n",
    "X_train_poly_tomerge = pd.DataFrame(poly_train, columns=poly_f.get_feature_names())\n",
    "X_test_poly_tomerge = pd.DataFrame(poly_test, columns=poly_f1.get_feature_names())\n",
    "\n",
    "X_train_poly = pd.concat([X, X_train_poly_tomerge], axis=1)\n",
    "X_test_poly = pd.concat([X_test, X_test_poly_tomerge], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x0': 'city_development_index', 'x1': 'company_size', 'x2': 'education_level'}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_poly = {f'x{i}':v for i,v in enumerate(to_poly_lst)}\n",
    "vars_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14368, 22), (4790, 22), (14368,), (4790,))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_poly, X_val_poly, y_train_poly, y_val_poly = train_test_split(X_train_poly, y, stratify=y, shuffle=True, random_state=1)\n",
    "X_train_poly.shape, X_val_poly.shape, y_train_poly.shape, y_val_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>city</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>gender</th>\n",
       "      <th>relevent_experience</th>\n",
       "      <th>enrolled_university</th>\n",
       "      <th>education_level</th>\n",
       "      <th>major_discipline</th>\n",
       "      <th>experience</th>\n",
       "      <th>company_size</th>\n",
       "      <th>...</th>\n",
       "      <th>training_hours</th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x0^2</th>\n",
       "      <th>x0 x1</th>\n",
       "      <th>x0 x2</th>\n",
       "      <th>x1^2</th>\n",
       "      <th>x1 x2</th>\n",
       "      <th>x2^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12751</th>\n",
       "      <td>0.147735</td>\n",
       "      <td>1.098572</td>\n",
       "      <td>-0.538003</td>\n",
       "      <td>0.203475</td>\n",
       "      <td>1.601582</td>\n",
       "      <td>-0.591065</td>\n",
       "      <td>-0.254614</td>\n",
       "      <td>-0.326356</td>\n",
       "      <td>-1.195199</td>\n",
       "      <td>-0.599850</td>\n",
       "      <td>...</td>\n",
       "      <td>2.108598</td>\n",
       "      <td>-0.538003</td>\n",
       "      <td>-0.254614</td>\n",
       "      <td>-0.599850</td>\n",
       "      <td>0.289448</td>\n",
       "      <td>0.136983</td>\n",
       "      <td>0.322721</td>\n",
       "      <td>0.064829</td>\n",
       "      <td>0.152730</td>\n",
       "      <td>0.359820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12061</th>\n",
       "      <td>-0.293801</td>\n",
       "      <td>0.561325</td>\n",
       "      <td>-1.655108</td>\n",
       "      <td>0.203475</td>\n",
       "      <td>-0.624383</td>\n",
       "      <td>-0.591065</td>\n",
       "      <td>-0.254614</td>\n",
       "      <td>-0.326356</td>\n",
       "      <td>0.278127</td>\n",
       "      <td>-0.249284</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.037533</td>\n",
       "      <td>-1.655108</td>\n",
       "      <td>-0.254614</td>\n",
       "      <td>-0.249284</td>\n",
       "      <td>2.739382</td>\n",
       "      <td>0.421414</td>\n",
       "      <td>0.412592</td>\n",
       "      <td>0.064829</td>\n",
       "      <td>0.063471</td>\n",
       "      <td>0.062143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18919</th>\n",
       "      <td>-1.680622</td>\n",
       "      <td>0.137182</td>\n",
       "      <td>0.741001</td>\n",
       "      <td>0.203475</td>\n",
       "      <td>1.601582</td>\n",
       "      <td>1.701364</td>\n",
       "      <td>-0.254614</td>\n",
       "      <td>-0.326356</td>\n",
       "      <td>0.425459</td>\n",
       "      <td>1.152978</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.221869</td>\n",
       "      <td>0.741001</td>\n",
       "      <td>-0.254614</td>\n",
       "      <td>1.152978</td>\n",
       "      <td>0.549082</td>\n",
       "      <td>-0.188669</td>\n",
       "      <td>0.854357</td>\n",
       "      <td>0.064829</td>\n",
       "      <td>-0.293565</td>\n",
       "      <td>1.329358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3215</th>\n",
       "      <td>0.836256</td>\n",
       "      <td>0.561325</td>\n",
       "      <td>-1.655108</td>\n",
       "      <td>0.203475</td>\n",
       "      <td>1.601582</td>\n",
       "      <td>-0.591065</td>\n",
       "      <td>-0.254614</td>\n",
       "      <td>-0.326356</td>\n",
       "      <td>-0.753201</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.804486</td>\n",
       "      <td>-1.655108</td>\n",
       "      <td>-0.254614</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>2.739382</td>\n",
       "      <td>0.421414</td>\n",
       "      <td>-1.328079</td>\n",
       "      <td>0.064829</td>\n",
       "      <td>-0.204306</td>\n",
       "      <td>0.643866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5273</th>\n",
       "      <td>-1.340211</td>\n",
       "      <td>0.137182</td>\n",
       "      <td>0.741001</td>\n",
       "      <td>0.203475</td>\n",
       "      <td>-0.624383</td>\n",
       "      <td>-0.591065</td>\n",
       "      <td>-0.254614</td>\n",
       "      <td>-0.326356</td>\n",
       "      <td>-0.900534</td>\n",
       "      <td>-0.950415</td>\n",
       "      <td>...</td>\n",
       "      <td>2.308353</td>\n",
       "      <td>0.741001</td>\n",
       "      <td>-0.254614</td>\n",
       "      <td>-0.950415</td>\n",
       "      <td>0.549082</td>\n",
       "      <td>-0.188669</td>\n",
       "      <td>-0.704258</td>\n",
       "      <td>0.064829</td>\n",
       "      <td>0.241989</td>\n",
       "      <td>0.903289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>-0.100083</td>\n",
       "      <td>-1.106970</td>\n",
       "      <td>0.741001</td>\n",
       "      <td>-3.530470</td>\n",
       "      <td>1.601582</td>\n",
       "      <td>-0.591065</td>\n",
       "      <td>-0.254614</td>\n",
       "      <td>3.064143</td>\n",
       "      <td>-0.900534</td>\n",
       "      <td>1.152978</td>\n",
       "      <td>...</td>\n",
       "      <td>1.675797</td>\n",
       "      <td>0.741001</td>\n",
       "      <td>-0.254614</td>\n",
       "      <td>1.152978</td>\n",
       "      <td>0.549082</td>\n",
       "      <td>-0.188669</td>\n",
       "      <td>0.854357</td>\n",
       "      <td>0.064829</td>\n",
       "      <td>-0.293565</td>\n",
       "      <td>1.329358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8701</th>\n",
       "      <td>-1.574504</td>\n",
       "      <td>-1.106970</td>\n",
       "      <td>0.741001</td>\n",
       "      <td>0.203475</td>\n",
       "      <td>-0.624383</td>\n",
       "      <td>-0.591065</td>\n",
       "      <td>-0.254614</td>\n",
       "      <td>-0.326356</td>\n",
       "      <td>1.162122</td>\n",
       "      <td>-0.950415</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.654670</td>\n",
       "      <td>0.741001</td>\n",
       "      <td>-0.254614</td>\n",
       "      <td>-0.950415</td>\n",
       "      <td>0.549082</td>\n",
       "      <td>-0.188669</td>\n",
       "      <td>-0.704258</td>\n",
       "      <td>0.064829</td>\n",
       "      <td>0.241989</td>\n",
       "      <td>0.903289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18883</th>\n",
       "      <td>0.096861</td>\n",
       "      <td>0.589601</td>\n",
       "      <td>0.571006</td>\n",
       "      <td>0.203475</td>\n",
       "      <td>-0.624383</td>\n",
       "      <td>-0.591065</td>\n",
       "      <td>-0.254614</td>\n",
       "      <td>-0.326356</td>\n",
       "      <td>1.604119</td>\n",
       "      <td>-0.249284</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.687962</td>\n",
       "      <td>0.571006</td>\n",
       "      <td>-0.254614</td>\n",
       "      <td>-0.249284</td>\n",
       "      <td>0.326048</td>\n",
       "      <td>-0.145386</td>\n",
       "      <td>-0.142343</td>\n",
       "      <td>0.064829</td>\n",
       "      <td>0.063471</td>\n",
       "      <td>0.062143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17051</th>\n",
       "      <td>-0.807226</td>\n",
       "      <td>0.165458</td>\n",
       "      <td>-0.497528</td>\n",
       "      <td>0.203475</td>\n",
       "      <td>-0.624383</td>\n",
       "      <td>-0.591065</td>\n",
       "      <td>-0.254614</td>\n",
       "      <td>-0.326356</td>\n",
       "      <td>-0.311203</td>\n",
       "      <td>-1.651546</td>\n",
       "      <td>...</td>\n",
       "      <td>1.659151</td>\n",
       "      <td>-0.497528</td>\n",
       "      <td>-0.254614</td>\n",
       "      <td>-1.651546</td>\n",
       "      <td>0.247535</td>\n",
       "      <td>0.126678</td>\n",
       "      <td>0.821691</td>\n",
       "      <td>0.064829</td>\n",
       "      <td>0.420508</td>\n",
       "      <td>2.727605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4200</th>\n",
       "      <td>-1.126934</td>\n",
       "      <td>-1.106970</td>\n",
       "      <td>0.741001</td>\n",
       "      <td>0.203475</td>\n",
       "      <td>-0.624383</td>\n",
       "      <td>-0.591065</td>\n",
       "      <td>-0.254614</td>\n",
       "      <td>3.064143</td>\n",
       "      <td>1.604119</td>\n",
       "      <td>0.101281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294163</td>\n",
       "      <td>0.741001</td>\n",
       "      <td>-0.254614</td>\n",
       "      <td>0.101281</td>\n",
       "      <td>0.549082</td>\n",
       "      <td>-0.188669</td>\n",
       "      <td>0.075050</td>\n",
       "      <td>0.064829</td>\n",
       "      <td>-0.025788</td>\n",
       "      <td>0.010258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14368 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       enrollee_id      city  city_development_index    gender  \\\n",
       "12751     0.147735  1.098572               -0.538003  0.203475   \n",
       "12061    -0.293801  0.561325               -1.655108  0.203475   \n",
       "18919    -1.680622  0.137182                0.741001  0.203475   \n",
       "3215      0.836256  0.561325               -1.655108  0.203475   \n",
       "5273     -1.340211  0.137182                0.741001  0.203475   \n",
       "...            ...       ...                     ...       ...   \n",
       "1231     -0.100083 -1.106970                0.741001 -3.530470   \n",
       "8701     -1.574504 -1.106970                0.741001  0.203475   \n",
       "18883     0.096861  0.589601                0.571006  0.203475   \n",
       "17051    -0.807226  0.165458               -0.497528  0.203475   \n",
       "4200     -1.126934 -1.106970                0.741001  0.203475   \n",
       "\n",
       "       relevent_experience  enrolled_university  education_level  \\\n",
       "12751             1.601582            -0.591065        -0.254614   \n",
       "12061            -0.624383            -0.591065        -0.254614   \n",
       "18919             1.601582             1.701364        -0.254614   \n",
       "3215              1.601582            -0.591065        -0.254614   \n",
       "5273             -0.624383            -0.591065        -0.254614   \n",
       "...                    ...                  ...              ...   \n",
       "1231              1.601582            -0.591065        -0.254614   \n",
       "8701             -0.624383            -0.591065        -0.254614   \n",
       "18883            -0.624383            -0.591065        -0.254614   \n",
       "17051            -0.624383            -0.591065        -0.254614   \n",
       "4200             -0.624383            -0.591065        -0.254614   \n",
       "\n",
       "       major_discipline  experience  company_size  ...  training_hours  \\\n",
       "12751         -0.326356   -1.195199     -0.599850  ...        2.108598   \n",
       "12061         -0.326356    0.278127     -0.249284  ...       -1.037533   \n",
       "18919         -0.326356    0.425459      1.152978  ...       -0.221869   \n",
       "3215          -0.326356   -0.753201      0.802413  ...       -0.804486   \n",
       "5273          -0.326356   -0.900534     -0.950415  ...        2.308353   \n",
       "...                 ...         ...           ...  ...             ...   \n",
       "1231           3.064143   -0.900534      1.152978  ...        1.675797   \n",
       "8701          -0.326356    1.162122     -0.950415  ...       -0.654670   \n",
       "18883         -0.326356    1.604119     -0.249284  ...       -0.687962   \n",
       "17051         -0.326356   -0.311203     -1.651546  ...        1.659151   \n",
       "4200           3.064143    1.604119      0.101281  ...        0.294163   \n",
       "\n",
       "             x0        x1        x2      x0^2     x0 x1     x0 x2      x1^2  \\\n",
       "12751 -0.538003 -0.254614 -0.599850  0.289448  0.136983  0.322721  0.064829   \n",
       "12061 -1.655108 -0.254614 -0.249284  2.739382  0.421414  0.412592  0.064829   \n",
       "18919  0.741001 -0.254614  1.152978  0.549082 -0.188669  0.854357  0.064829   \n",
       "3215  -1.655108 -0.254614  0.802413  2.739382  0.421414 -1.328079  0.064829   \n",
       "5273   0.741001 -0.254614 -0.950415  0.549082 -0.188669 -0.704258  0.064829   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "1231   0.741001 -0.254614  1.152978  0.549082 -0.188669  0.854357  0.064829   \n",
       "8701   0.741001 -0.254614 -0.950415  0.549082 -0.188669 -0.704258  0.064829   \n",
       "18883  0.571006 -0.254614 -0.249284  0.326048 -0.145386 -0.142343  0.064829   \n",
       "17051 -0.497528 -0.254614 -1.651546  0.247535  0.126678  0.821691  0.064829   \n",
       "4200   0.741001 -0.254614  0.101281  0.549082 -0.188669  0.075050  0.064829   \n",
       "\n",
       "          x1 x2      x2^2  \n",
       "12751  0.152730  0.359820  \n",
       "12061  0.063471  0.062143  \n",
       "18919 -0.293565  1.329358  \n",
       "3215  -0.204306  0.643866  \n",
       "5273   0.241989  0.903289  \n",
       "...         ...       ...  \n",
       "1231  -0.293565  1.329358  \n",
       "8701   0.241989  0.903289  \n",
       "18883  0.063471  0.062143  \n",
       "17051  0.420508  2.727605  \n",
       "4200  -0.025788  0.010258  \n",
       "\n",
       "[14368 rows x 22 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오버샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversample = SMOTE()\n",
    "# sm = SMOTE(ratio='auto', kind='regular')\n",
    "sm = SMOTE(random_state=0)\n",
    "X_train_ovsp, y_train_ovsp = sm.fit_resample(X_train, list(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=0)\n",
    "X_train_poly_ovsp, y_train_poly_ovsp = sm.fit_resample(X_train_poly, list(y_train_poly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21570, 13), (14368, 13), (21570, 22), (14368, 22))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ovsp.shape, X_train.shape, X_train_poly_ovsp.shape, X_train_poly.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "# XGBoost_randomized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = dict(\n",
    "    n_estimators=[100, 200, 300, 400, 500],\n",
    "    learning_rate=[0.001,0.005,0.01,0.05,0.1,0.5],\n",
    "    max_depth=range(1, 7)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\inje.jeong\\anaconda3\\envs\\ml\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:57:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.5, max_delta_step=0, max_depth=2,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=200, n_jobs=12, num_parallel_tree=1, random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=200,\n",
    "                   learning_rate=0.5,\n",
    "                   max_depth=2,\n",
    "                   random_state=1)\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nopoly-nooversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\inje.jeong\\anaconda3\\envs\\ml\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:57:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           gpu_id=-1, importance_type='gain',\n",
       "                                           interaction_constraints='',\n",
       "                                           learning_rate=0.5, max_delta_step=0,\n",
       "                                           max_depth=2, min_child_weight=1,\n",
       "                                           missing=nan,\n",
       "                                           monotone_constraints='()',\n",
       "                                           n_estimators=200, n_jobs=12,\n",
       "                                           num_parallel_tree=1, random_state=1,\n",
       "                                           reg_alpha=0, reg_lambda=1,\n",
       "                                           scale_pos_weight=1, subsample=1,\n",
       "                                           tree_method='exact',\n",
       "                                           validate_parameters=1,\n",
       "                                           verbosity=None),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': [0.001, 0.005, 0.01,\n",
       "                                                          0.05, 0.1, 0.5],\n",
       "                                        'max_depth': range(1, 7),\n",
       "                                        'n_estimators': [100, 200, 300, 400,\n",
       "                                                         500]},\n",
       "                   random_state=1, scoring='accuracy')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_xgb = RandomizedSearchCV(xgb,\n",
    "                             param_distributions=param,\n",
    "                             n_iter=10,\n",
    "                             scoring='accuracy',\n",
    "                             cv=3,\n",
    "                             n_jobs=-1,\n",
    "                             random_state=1\n",
    "                             )\n",
    "random_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city_development_index    0.308716\n",
       "company_size              0.284353\n",
       "education_level           0.098494\n",
       "company_type              0.058500\n",
       "relevent_experience       0.043561\n",
       "last_new_job              0.032939\n",
       "experience                0.030608\n",
       "enrolled_university       0.029641\n",
       "city                      0.027563\n",
       "major_discipline          0.023135\n",
       "enrollee_id               0.023065\n",
       "training_hours            0.021272\n",
       "gender                    0.018153\n",
       "dtype: float32"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "be = random_xgb.best_estimator_\n",
    "pd.Series(be.feature_importances_, index=X_train.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.781230</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.011403</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 5, 'learnin...</td>\n",
       "      <td>0.798330</td>\n",
       "      <td>0.786594</td>\n",
       "      <td>0.792023</td>\n",
       "      <td>0.792316</td>\n",
       "      <td>0.004795</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.922286</td>\n",
       "      <td>0.016012</td>\n",
       "      <td>0.014640</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 5, 'learnin...</td>\n",
       "      <td>0.798121</td>\n",
       "      <td>0.786385</td>\n",
       "      <td>0.790979</td>\n",
       "      <td>0.791829</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.320877</td>\n",
       "      <td>0.061077</td>\n",
       "      <td>0.012857</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 6, 'learnin...</td>\n",
       "      <td>0.796033</td>\n",
       "      <td>0.789309</td>\n",
       "      <td>0.789726</td>\n",
       "      <td>0.791690</td>\n",
       "      <td>0.003076</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.447668</td>\n",
       "      <td>0.082990</td>\n",
       "      <td>0.012531</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'n_estimators': 300, 'max_depth': 5, 'learnin...</td>\n",
       "      <td>0.792902</td>\n",
       "      <td>0.788474</td>\n",
       "      <td>0.789100</td>\n",
       "      <td>0.790158</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.353213</td>\n",
       "      <td>0.076021</td>\n",
       "      <td>0.009454</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>300</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 300, 'max_depth': 2, 'learnin...</td>\n",
       "      <td>0.789562</td>\n",
       "      <td>0.784506</td>\n",
       "      <td>0.785341</td>\n",
       "      <td>0.786470</td>\n",
       "      <td>0.002213</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.950103</td>\n",
       "      <td>0.058845</td>\n",
       "      <td>0.029462</td>\n",
       "      <td>0.015458</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 2, 'learnin...</td>\n",
       "      <td>0.788935</td>\n",
       "      <td>0.784297</td>\n",
       "      <td>0.783462</td>\n",
       "      <td>0.785565</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.191626</td>\n",
       "      <td>0.031925</td>\n",
       "      <td>0.007821</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 2, 'learnin...</td>\n",
       "      <td>0.782672</td>\n",
       "      <td>0.780956</td>\n",
       "      <td>0.784089</td>\n",
       "      <td>0.782572</td>\n",
       "      <td>0.001281</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.341498</td>\n",
       "      <td>0.094911</td>\n",
       "      <td>0.012857</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 4, 'learnin...</td>\n",
       "      <td>0.782463</td>\n",
       "      <td>0.779703</td>\n",
       "      <td>0.784089</td>\n",
       "      <td>0.782085</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.911180</td>\n",
       "      <td>0.062282</td>\n",
       "      <td>0.021814</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 2, 'learnin...</td>\n",
       "      <td>0.781420</td>\n",
       "      <td>0.781374</td>\n",
       "      <td>0.782209</td>\n",
       "      <td>0.781668</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.542412</td>\n",
       "      <td>0.049038</td>\n",
       "      <td>0.016449</td>\n",
       "      <td>0.006062</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 3, 'learnin...</td>\n",
       "      <td>0.783507</td>\n",
       "      <td>0.772813</td>\n",
       "      <td>0.780330</td>\n",
       "      <td>0.778883</td>\n",
       "      <td>0.004484</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "8       2.781230      0.010593         0.011403        0.003486   \n",
       "5      10.922286      0.016012         0.014640        0.001380   \n",
       "0       8.320877      0.061077         0.012857        0.000240   \n",
       "1       9.447668      0.082990         0.012531        0.001892   \n",
       "9       2.353213      0.076021         0.009454        0.000624   \n",
       "2       5.950103      0.058845         0.029462        0.015458   \n",
       "4       1.191626      0.031925         0.007821        0.000399   \n",
       "7       7.341498      0.094911         0.012857        0.001961   \n",
       "6       4.911180      0.062282         0.021814        0.006642   \n",
       "3       3.542412      0.049038         0.016449        0.006062   \n",
       "\n",
       "  param_n_estimators param_max_depth param_learning_rate  \\\n",
       "8                100               5                0.05   \n",
       "5                500               5               0.005   \n",
       "0                200               6                0.05   \n",
       "1                300               5                0.05   \n",
       "9                300               2                 0.1   \n",
       "2                500               2                0.05   \n",
       "4                100               2               0.005   \n",
       "7                500               4               0.001   \n",
       "6                500               2                0.01   \n",
       "3                200               3                 0.5   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "8  {'n_estimators': 100, 'max_depth': 5, 'learnin...           0.798330   \n",
       "5  {'n_estimators': 500, 'max_depth': 5, 'learnin...           0.798121   \n",
       "0  {'n_estimators': 200, 'max_depth': 6, 'learnin...           0.796033   \n",
       "1  {'n_estimators': 300, 'max_depth': 5, 'learnin...           0.792902   \n",
       "9  {'n_estimators': 300, 'max_depth': 2, 'learnin...           0.789562   \n",
       "2  {'n_estimators': 500, 'max_depth': 2, 'learnin...           0.788935   \n",
       "4  {'n_estimators': 100, 'max_depth': 2, 'learnin...           0.782672   \n",
       "7  {'n_estimators': 500, 'max_depth': 4, 'learnin...           0.782463   \n",
       "6  {'n_estimators': 500, 'max_depth': 2, 'learnin...           0.781420   \n",
       "3  {'n_estimators': 200, 'max_depth': 3, 'learnin...           0.783507   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "8           0.786594           0.792023         0.792316        0.004795   \n",
       "5           0.786385           0.790979         0.791829        0.004829   \n",
       "0           0.789309           0.789726         0.791690        0.003076   \n",
       "1           0.788474           0.789100         0.790158        0.001957   \n",
       "9           0.784506           0.785341         0.786470        0.002213   \n",
       "2           0.784297           0.783462         0.785565        0.002407   \n",
       "4           0.780956           0.784089         0.782572        0.001281   \n",
       "7           0.779703           0.784089         0.782085        0.001810   \n",
       "6           0.781374           0.782209         0.781668        0.000383   \n",
       "3           0.772813           0.780330         0.778883        0.004484   \n",
       "\n",
       "   rank_test_score  \n",
       "8                1  \n",
       "5                2  \n",
       "0                3  \n",
       "1                4  \n",
       "9                5  \n",
       "2                6  \n",
       "4                7  \n",
       "7                8  \n",
       "6                9  \n",
       "3               10  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(random_xgb.cv_results_).sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy : 0.8167455456570156\n",
      "validation accuracy : 0.7962421711899791\n"
     ]
    }
   ],
   "source": [
    "pred_train = random_xgb.predict(X_train)\n",
    "pred_val = random_xgb.predict(X_val)\n",
    "\n",
    "print('train accuracy :', accuracy_score(y_train, pred_train))\n",
    "print('validation accuracy :', accuracy_score(y_val, pred_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### poly-nooversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\inje.jeong\\anaconda3\\envs\\ml\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:03:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           gpu_id=-1, importance_type='gain',\n",
       "                                           interaction_constraints='',\n",
       "                                           learning_rate=0.5, max_delta_step=0,\n",
       "                                           max_depth=2, min_child_weight=1,\n",
       "                                           missing=nan,\n",
       "                                           monotone_constraints='()',\n",
       "                                           n_estimators=200, n_jobs=12,\n",
       "                                           num_parallel_tree=1, random_state=1,\n",
       "                                           reg_alpha=0, reg_lambda=1,\n",
       "                                           scale_pos_weight=1, subsample=1,\n",
       "                                           tree_method='exact',\n",
       "                                           validate_parameters=1,\n",
       "                                           verbosity=None),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': [0.001, 0.005, 0.01,\n",
       "                                                          0.05, 0.1, 0.5],\n",
       "                                        'max_depth': range(1, 7),\n",
       "                                        'n_estimators': [100, 200, 300, 400,\n",
       "                                                         500]},\n",
       "                   random_state=1, scoring='accuracy')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_xgb_poly = RandomizedSearchCV(xgb,\n",
    "                             param_distributions=param,\n",
    "                             n_iter=10,\n",
    "                             scoring='accuracy',\n",
    "                             cv=3,\n",
    "                             n_jobs=-1,\n",
    "                             random_state=1\n",
    "                             )\n",
    "random_xgb_poly.fit(X_train_poly, y_train_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company_size              0.296272\n",
       "city_development_index    0.245560\n",
       "x1^2                      0.112375\n",
       "x0^2                      0.076204\n",
       "x0 x2                     0.054392\n",
       "relevent_experience       0.039928\n",
       "company_type              0.024120\n",
       "last_new_job              0.020131\n",
       "experience                0.018034\n",
       "enrolled_university       0.014673\n",
       "x0 x1                     0.013214\n",
       "x2^2                      0.012214\n",
       "x1 x2                     0.012100\n",
       "major_discipline          0.010724\n",
       "city                      0.010476\n",
       "education_level           0.010207\n",
       "enrollee_id               0.010153\n",
       "gender                    0.009709\n",
       "training_hours            0.009514\n",
       "x0                        0.000000\n",
       "x1                        0.000000\n",
       "x2                        0.000000\n",
       "dtype: float32"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "be_poly = random_xgb_poly.best_estimator_\n",
    "pd.Series(be_poly.feature_importances_, index=X_train_poly.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16.709105</td>\n",
       "      <td>0.040552</td>\n",
       "      <td>0.019382</td>\n",
       "      <td>0.002437</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 5, 'learnin...</td>\n",
       "      <td>0.801879</td>\n",
       "      <td>0.793067</td>\n",
       "      <td>0.794529</td>\n",
       "      <td>0.796492</td>\n",
       "      <td>0.003856</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.719409</td>\n",
       "      <td>0.082738</td>\n",
       "      <td>0.015953</td>\n",
       "      <td>0.004625</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 5, 'learnin...</td>\n",
       "      <td>0.801044</td>\n",
       "      <td>0.789726</td>\n",
       "      <td>0.792859</td>\n",
       "      <td>0.794543</td>\n",
       "      <td>0.004771</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.764463</td>\n",
       "      <td>0.137971</td>\n",
       "      <td>0.019194</td>\n",
       "      <td>0.005765</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'n_estimators': 300, 'max_depth': 5, 'learnin...</td>\n",
       "      <td>0.798330</td>\n",
       "      <td>0.788265</td>\n",
       "      <td>0.791606</td>\n",
       "      <td>0.792733</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.626392</td>\n",
       "      <td>0.040837</td>\n",
       "      <td>0.012050</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 2, 'learnin...</td>\n",
       "      <td>0.794990</td>\n",
       "      <td>0.789309</td>\n",
       "      <td>0.790353</td>\n",
       "      <td>0.791550</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.510986</td>\n",
       "      <td>0.183664</td>\n",
       "      <td>0.027697</td>\n",
       "      <td>0.010086</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 6, 'learnin...</td>\n",
       "      <td>0.794363</td>\n",
       "      <td>0.791188</td>\n",
       "      <td>0.786803</td>\n",
       "      <td>0.790785</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.971837</td>\n",
       "      <td>0.047891</td>\n",
       "      <td>0.013833</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>300</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 300, 'max_depth': 2, 'learnin...</td>\n",
       "      <td>0.796660</td>\n",
       "      <td>0.786177</td>\n",
       "      <td>0.788891</td>\n",
       "      <td>0.790576</td>\n",
       "      <td>0.004442</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.079908</td>\n",
       "      <td>0.248717</td>\n",
       "      <td>0.021789</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 4, 'learnin...</td>\n",
       "      <td>0.795198</td>\n",
       "      <td>0.786803</td>\n",
       "      <td>0.788474</td>\n",
       "      <td>0.790158</td>\n",
       "      <td>0.003628</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.023155</td>\n",
       "      <td>0.072801</td>\n",
       "      <td>0.021966</td>\n",
       "      <td>0.005526</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 2, 'learnin...</td>\n",
       "      <td>0.789562</td>\n",
       "      <td>0.780956</td>\n",
       "      <td>0.783671</td>\n",
       "      <td>0.784730</td>\n",
       "      <td>0.003592</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.995921</td>\n",
       "      <td>0.014192</td>\n",
       "      <td>0.011230</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 2, 'learnin...</td>\n",
       "      <td>0.782672</td>\n",
       "      <td>0.781374</td>\n",
       "      <td>0.784089</td>\n",
       "      <td>0.782712</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.264971</td>\n",
       "      <td>0.018754</td>\n",
       "      <td>0.018544</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 3, 'learnin...</td>\n",
       "      <td>0.779541</td>\n",
       "      <td>0.777824</td>\n",
       "      <td>0.785341</td>\n",
       "      <td>0.780902</td>\n",
       "      <td>0.003216</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "5      16.709105      0.040552         0.019382        0.002437   \n",
       "8       4.719409      0.082738         0.015953        0.004625   \n",
       "1       9.764463      0.137971         0.019194        0.005765   \n",
       "2       5.626392      0.040837         0.012050        0.000239   \n",
       "0       8.510986      0.183664         0.027697        0.010086   \n",
       "9       4.971837      0.047891         0.013833        0.001279   \n",
       "7      12.079908      0.248717         0.021789        0.002296   \n",
       "6       6.023155      0.072801         0.021966        0.005526   \n",
       "4       0.995921      0.014192         0.011230        0.000682   \n",
       "3       3.264971      0.018754         0.018544        0.002108   \n",
       "\n",
       "  param_n_estimators param_max_depth param_learning_rate  \\\n",
       "5                500               5               0.005   \n",
       "8                100               5                0.05   \n",
       "1                300               5                0.05   \n",
       "2                500               2                0.05   \n",
       "0                200               6                0.05   \n",
       "9                300               2                 0.1   \n",
       "7                500               4               0.001   \n",
       "6                500               2                0.01   \n",
       "4                100               2               0.005   \n",
       "3                200               3                 0.5   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "5  {'n_estimators': 500, 'max_depth': 5, 'learnin...           0.801879   \n",
       "8  {'n_estimators': 100, 'max_depth': 5, 'learnin...           0.801044   \n",
       "1  {'n_estimators': 300, 'max_depth': 5, 'learnin...           0.798330   \n",
       "2  {'n_estimators': 500, 'max_depth': 2, 'learnin...           0.794990   \n",
       "0  {'n_estimators': 200, 'max_depth': 6, 'learnin...           0.794363   \n",
       "9  {'n_estimators': 300, 'max_depth': 2, 'learnin...           0.796660   \n",
       "7  {'n_estimators': 500, 'max_depth': 4, 'learnin...           0.795198   \n",
       "6  {'n_estimators': 500, 'max_depth': 2, 'learnin...           0.789562   \n",
       "4  {'n_estimators': 100, 'max_depth': 2, 'learnin...           0.782672   \n",
       "3  {'n_estimators': 200, 'max_depth': 3, 'learnin...           0.779541   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "5           0.793067           0.794529         0.796492        0.003856   \n",
       "8           0.789726           0.792859         0.794543        0.004771   \n",
       "1           0.788265           0.791606         0.792733        0.004186   \n",
       "2           0.789309           0.790353         0.791550        0.002469   \n",
       "0           0.791188           0.786803         0.790785        0.003100   \n",
       "9           0.786177           0.788891         0.790576        0.004442   \n",
       "7           0.786803           0.788474         0.790158        0.003628   \n",
       "6           0.780956           0.783671         0.784730        0.003592   \n",
       "4           0.781374           0.784089         0.782712        0.001109   \n",
       "3           0.777824           0.785341         0.780902        0.003216   \n",
       "\n",
       "   rank_test_score  \n",
       "5                1  \n",
       "8                2  \n",
       "1                3  \n",
       "2                4  \n",
       "0                5  \n",
       "9                6  \n",
       "7                7  \n",
       "6                8  \n",
       "4                9  \n",
       "3               10  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(random_xgb_poly.cv_results_).sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy : 0.8104816258351893\n",
      "validation accuracy : 0.7960334029227557\n"
     ]
    }
   ],
   "source": [
    "pred_train_poly = random_xgb_poly.predict(X_train_poly)\n",
    "pred_val_poly = random_xgb_poly.predict(X_val_poly)\n",
    "\n",
    "print('train accuracy :', accuracy_score(y_train_poly, pred_train_poly))\n",
    "print('validation accuracy :', accuracy_score(y_val_poly, pred_val_poly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nopoly-oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\inje.jeong\\anaconda3\\envs\\ml\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:13:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           gpu_id=-1, importance_type='gain',\n",
       "                                           interaction_constraints='',\n",
       "                                           learning_rate=0.5, max_delta_step=0,\n",
       "                                           max_depth=2, min_child_weight=1,\n",
       "                                           missing=nan,\n",
       "                                           monotone_constraints='()',\n",
       "                                           n_estimators=200, n_jobs=12,\n",
       "                                           num_parallel_tree=1, random_state=1,\n",
       "                                           reg_alpha=0, reg_lambda=1,\n",
       "                                           scale_pos_weight=1, subsample=1,\n",
       "                                           tree_method='exact',\n",
       "                                           validate_parameters=1,\n",
       "                                           verbosity=None),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': [0.001, 0.005, 0.01,\n",
       "                                                          0.05, 0.1, 0.5],\n",
       "                                        'max_depth': range(1, 7),\n",
       "                                        'n_estimators': [100, 200, 300, 400,\n",
       "                                                         500]},\n",
       "                   random_state=1, scoring='accuracy')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_xgb_ovsp = RandomizedSearchCV(xgb,\n",
    "                             param_distributions=param,\n",
    "                             n_iter=10,\n",
    "                             scoring='accuracy',\n",
    "                             cv=3,\n",
    "                             n_jobs=-1,\n",
    "                             random_state=1\n",
    "                             )\n",
    "random_xgb_ovsp.fit(X_train_ovsp, y_train_ovsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company_type              0.233673\n",
       "city_development_index    0.173910\n",
       "company_size              0.161064\n",
       "education_level           0.113087\n",
       "last_new_job              0.093687\n",
       "experience                0.067578\n",
       "enrolled_university       0.052341\n",
       "city                      0.036737\n",
       "relevent_experience       0.028717\n",
       "training_hours            0.015599\n",
       "enrollee_id               0.010632\n",
       "major_discipline          0.007751\n",
       "gender                    0.005225\n",
       "dtype: float32"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "be_ovsp = random_xgb_ovsp.best_estimator_\n",
    "pd.Series(be_ovsp.feature_importances_, index=X_train_ovsp.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.186937</td>\n",
       "      <td>0.020430</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 5, 'learnin...</td>\n",
       "      <td>0.710709</td>\n",
       "      <td>0.853268</td>\n",
       "      <td>0.867316</td>\n",
       "      <td>0.810431</td>\n",
       "      <td>0.070747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.365206</td>\n",
       "      <td>0.110753</td>\n",
       "      <td>0.021640</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 5, 'learnin...</td>\n",
       "      <td>0.744924</td>\n",
       "      <td>0.826565</td>\n",
       "      <td>0.838526</td>\n",
       "      <td>0.803338</td>\n",
       "      <td>0.041593</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.595559</td>\n",
       "      <td>0.136370</td>\n",
       "      <td>0.019206</td>\n",
       "      <td>0.002401</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 6, 'learnin...</td>\n",
       "      <td>0.619193</td>\n",
       "      <td>0.882476</td>\n",
       "      <td>0.897218</td>\n",
       "      <td>0.799629</td>\n",
       "      <td>0.127729</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.523465</td>\n",
       "      <td>0.093100</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.004193</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'n_estimators': 300, 'max_depth': 5, 'learnin...</td>\n",
       "      <td>0.595549</td>\n",
       "      <td>0.885396</td>\n",
       "      <td>0.898748</td>\n",
       "      <td>0.793231</td>\n",
       "      <td>0.139888</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.453749</td>\n",
       "      <td>0.137309</td>\n",
       "      <td>0.015302</td>\n",
       "      <td>0.003087</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 2, 'learnin...</td>\n",
       "      <td>0.640890</td>\n",
       "      <td>0.859110</td>\n",
       "      <td>0.871627</td>\n",
       "      <td>0.790542</td>\n",
       "      <td>0.105943</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.029065</td>\n",
       "      <td>0.018344</td>\n",
       "      <td>0.012375</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>300</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 300, 'max_depth': 2, 'learnin...</td>\n",
       "      <td>0.621836</td>\n",
       "      <td>0.869263</td>\n",
       "      <td>0.880111</td>\n",
       "      <td>0.790403</td>\n",
       "      <td>0.119277</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.739917</td>\n",
       "      <td>0.017151</td>\n",
       "      <td>0.015148</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 2, 'learnin...</td>\n",
       "      <td>0.757441</td>\n",
       "      <td>0.787761</td>\n",
       "      <td>0.798192</td>\n",
       "      <td>0.781131</td>\n",
       "      <td>0.017284</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.280045</td>\n",
       "      <td>0.090715</td>\n",
       "      <td>0.013995</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 3, 'learnin...</td>\n",
       "      <td>0.524618</td>\n",
       "      <td>0.898748</td>\n",
       "      <td>0.906815</td>\n",
       "      <td>0.776727</td>\n",
       "      <td>0.178299</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.277979</td>\n",
       "      <td>0.060324</td>\n",
       "      <td>0.021002</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 4, 'learnin...</td>\n",
       "      <td>0.751043</td>\n",
       "      <td>0.778860</td>\n",
       "      <td>0.786092</td>\n",
       "      <td>0.771998</td>\n",
       "      <td>0.015109</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.467173</td>\n",
       "      <td>0.008698</td>\n",
       "      <td>0.012701</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 2, 'learnin...</td>\n",
       "      <td>0.735327</td>\n",
       "      <td>0.743394</td>\n",
       "      <td>0.754381</td>\n",
       "      <td>0.744367</td>\n",
       "      <td>0.007809</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "8       3.186937      0.020430         0.014006        0.001017   \n",
       "5      13.365206      0.110753         0.021640        0.002188   \n",
       "0      10.595559      0.136370         0.019206        0.002401   \n",
       "1      11.523465      0.093100         0.020833        0.004193   \n",
       "2       7.453749      0.137309         0.015302        0.003087   \n",
       "9       3.029065      0.018344         0.012375        0.001406   \n",
       "6       5.739917      0.017151         0.015148        0.000797   \n",
       "3       4.280045      0.090715         0.013995        0.001865   \n",
       "7       9.277979      0.060324         0.021002        0.001594   \n",
       "4       1.467173      0.008698         0.012701        0.001196   \n",
       "\n",
       "  param_n_estimators param_max_depth param_learning_rate  \\\n",
       "8                100               5                0.05   \n",
       "5                500               5               0.005   \n",
       "0                200               6                0.05   \n",
       "1                300               5                0.05   \n",
       "2                500               2                0.05   \n",
       "9                300               2                 0.1   \n",
       "6                500               2                0.01   \n",
       "3                200               3                 0.5   \n",
       "7                500               4               0.001   \n",
       "4                100               2               0.005   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "8  {'n_estimators': 100, 'max_depth': 5, 'learnin...           0.710709   \n",
       "5  {'n_estimators': 500, 'max_depth': 5, 'learnin...           0.744924   \n",
       "0  {'n_estimators': 200, 'max_depth': 6, 'learnin...           0.619193   \n",
       "1  {'n_estimators': 300, 'max_depth': 5, 'learnin...           0.595549   \n",
       "2  {'n_estimators': 500, 'max_depth': 2, 'learnin...           0.640890   \n",
       "9  {'n_estimators': 300, 'max_depth': 2, 'learnin...           0.621836   \n",
       "6  {'n_estimators': 500, 'max_depth': 2, 'learnin...           0.757441   \n",
       "3  {'n_estimators': 200, 'max_depth': 3, 'learnin...           0.524618   \n",
       "7  {'n_estimators': 500, 'max_depth': 4, 'learnin...           0.751043   \n",
       "4  {'n_estimators': 100, 'max_depth': 2, 'learnin...           0.735327   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "8           0.853268           0.867316         0.810431        0.070747   \n",
       "5           0.826565           0.838526         0.803338        0.041593   \n",
       "0           0.882476           0.897218         0.799629        0.127729   \n",
       "1           0.885396           0.898748         0.793231        0.139888   \n",
       "2           0.859110           0.871627         0.790542        0.105943   \n",
       "9           0.869263           0.880111         0.790403        0.119277   \n",
       "6           0.787761           0.798192         0.781131        0.017284   \n",
       "3           0.898748           0.906815         0.776727        0.178299   \n",
       "7           0.778860           0.786092         0.771998        0.015109   \n",
       "4           0.743394           0.754381         0.744367        0.007809   \n",
       "\n",
       "   rank_test_score  \n",
       "8                1  \n",
       "5                2  \n",
       "0                3  \n",
       "1                4  \n",
       "2                5  \n",
       "9                6  \n",
       "6                7  \n",
       "3                8  \n",
       "7                9  \n",
       "4               10  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(random_xgb_ovsp.cv_results_).sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy : 0.8423273064441353\n",
      "validation accuracy : 0.786847599164927\n"
     ]
    }
   ],
   "source": [
    "pred_train_ovsp = random_xgb_ovsp.predict(X_train_ovsp)\n",
    "pred_val_ovsp = random_xgb_ovsp.predict(X_val)\n",
    "\n",
    "print('train accuracy :', accuracy_score(y_train_ovsp, pred_train_ovsp))\n",
    "print('validation accuracy :', accuracy_score(y_val, pred_val_ovsp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### poly-oversampleling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\inje.jeong\\anaconda3\\envs\\ml\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:15:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           gpu_id=-1, importance_type='gain',\n",
       "                                           interaction_constraints='',\n",
       "                                           learning_rate=0.5, max_delta_step=0,\n",
       "                                           max_depth=2, min_child_weight=1,\n",
       "                                           missing=nan,\n",
       "                                           monotone_constraints='()',\n",
       "                                           n_estimators=200, n_jobs=12,\n",
       "                                           num_parallel_tree=1, random_state=1,\n",
       "                                           reg_alpha=0, reg_lambda=1,\n",
       "                                           scale_pos_weight=1, subsample=1,\n",
       "                                           tree_method='exact',\n",
       "                                           validate_parameters=1,\n",
       "                                           verbosity=None),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': [0.001, 0.005, 0.01,\n",
       "                                                          0.05, 0.1, 0.5],\n",
       "                                        'max_depth': range(1, 7),\n",
       "                                        'n_estimators': [100, 200, 300, 400,\n",
       "                                                         500]},\n",
       "                   random_state=1, scoring='accuracy')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_xgb_poly_ovsp = RandomizedSearchCV(xgb,\n",
    "                             param_distributions=param,\n",
    "                             n_iter=10,\n",
    "                             scoring='accuracy',\n",
    "                             cv=3,\n",
    "                             n_jobs=-1,\n",
    "                             random_state=1\n",
    "                             )\n",
    "random_xgb_poly_ovsp.fit(X_train_poly_ovsp, y_train_poly_ovsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x0^2                      0.260578\n",
       "company_size              0.147483\n",
       "company_type              0.116479\n",
       "x1^2                      0.085367\n",
       "last_new_job              0.071151\n",
       "city_development_index    0.059949\n",
       "enrolled_university       0.057367\n",
       "x0 x2                     0.036990\n",
       "relevent_experience       0.035466\n",
       "experience                0.031004\n",
       "x2^2                      0.025883\n",
       "city                      0.016636\n",
       "x1 x2                     0.014887\n",
       "training_hours            0.010659\n",
       "x0 x1                     0.007049\n",
       "enrollee_id               0.006799\n",
       "education_level           0.006708\n",
       "major_discipline          0.005044\n",
       "gender                    0.004500\n",
       "x0                        0.000000\n",
       "x1                        0.000000\n",
       "x2                        0.000000\n",
       "dtype: float32"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "be_poly_ovsp = random_xgb_poly_ovsp.best_estimator_\n",
    "pd.Series(be_poly_ovsp.feature_importances_, index=X_train_poly_ovsp.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.719591</td>\n",
       "      <td>0.261055</td>\n",
       "      <td>0.021478</td>\n",
       "      <td>0.005491</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 5, 'learnin...</td>\n",
       "      <td>0.731154</td>\n",
       "      <td>0.859388</td>\n",
       "      <td>0.865090</td>\n",
       "      <td>0.818544</td>\n",
       "      <td>0.061838</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21.474328</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.020507</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 5, 'learnin...</td>\n",
       "      <td>0.760083</td>\n",
       "      <td>0.838248</td>\n",
       "      <td>0.843115</td>\n",
       "      <td>0.813815</td>\n",
       "      <td>0.038046</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.666732</td>\n",
       "      <td>0.612302</td>\n",
       "      <td>0.017099</td>\n",
       "      <td>0.001382</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 6, 'learnin...</td>\n",
       "      <td>0.630181</td>\n",
       "      <td>0.886092</td>\n",
       "      <td>0.895132</td>\n",
       "      <td>0.803802</td>\n",
       "      <td>0.122824</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.787612</td>\n",
       "      <td>0.144927</td>\n",
       "      <td>0.017412</td>\n",
       "      <td>0.004627</td>\n",
       "      <td>300</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 300, 'max_depth': 2, 'learnin...</td>\n",
       "      <td>0.642003</td>\n",
       "      <td>0.869263</td>\n",
       "      <td>0.876634</td>\n",
       "      <td>0.795967</td>\n",
       "      <td>0.108910</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.542342</td>\n",
       "      <td>0.236605</td>\n",
       "      <td>0.020677</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'n_estimators': 300, 'max_depth': 5, 'learnin...</td>\n",
       "      <td>0.597079</td>\n",
       "      <td>0.889708</td>\n",
       "      <td>0.894854</td>\n",
       "      <td>0.793880</td>\n",
       "      <td>0.139175</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.451078</td>\n",
       "      <td>0.017842</td>\n",
       "      <td>0.019207</td>\n",
       "      <td>0.001891</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 2, 'learnin...</td>\n",
       "      <td>0.650209</td>\n",
       "      <td>0.857858</td>\n",
       "      <td>0.868150</td>\n",
       "      <td>0.792072</td>\n",
       "      <td>0.100401</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.515727</td>\n",
       "      <td>0.190381</td>\n",
       "      <td>0.040748</td>\n",
       "      <td>0.010307</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 2, 'learnin...</td>\n",
       "      <td>0.758554</td>\n",
       "      <td>0.784979</td>\n",
       "      <td>0.797914</td>\n",
       "      <td>0.780482</td>\n",
       "      <td>0.016380</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.246681</td>\n",
       "      <td>0.057999</td>\n",
       "      <td>0.019050</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 3, 'learnin...</td>\n",
       "      <td>0.527816</td>\n",
       "      <td>0.899444</td>\n",
       "      <td>0.908067</td>\n",
       "      <td>0.778442</td>\n",
       "      <td>0.177254</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16.310473</td>\n",
       "      <td>0.141242</td>\n",
       "      <td>0.025415</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 4, 'learnin...</td>\n",
       "      <td>0.751599</td>\n",
       "      <td>0.769680</td>\n",
       "      <td>0.787900</td>\n",
       "      <td>0.769726</td>\n",
       "      <td>0.014820</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.603732</td>\n",
       "      <td>0.016060</td>\n",
       "      <td>0.012363</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 2, 'learnin...</td>\n",
       "      <td>0.739638</td>\n",
       "      <td>0.741586</td>\n",
       "      <td>0.753129</td>\n",
       "      <td>0.744784</td>\n",
       "      <td>0.005954</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "8       6.719591      0.261055         0.021478        0.005491   \n",
       "5      21.474328      0.100275         0.020507        0.001428   \n",
       "0      11.666732      0.612302         0.017099        0.001382   \n",
       "9       5.787612      0.144927         0.017412        0.004627   \n",
       "1      13.542342      0.236605         0.020677        0.002842   \n",
       "2       8.451078      0.017842         0.019207        0.001891   \n",
       "6       8.515727      0.190381         0.040748        0.010307   \n",
       "3       5.246681      0.057999         0.019050        0.002108   \n",
       "7      16.310473      0.141242         0.025415        0.004212   \n",
       "4       1.603732      0.016060         0.012363        0.000460   \n",
       "\n",
       "  param_n_estimators param_max_depth param_learning_rate  \\\n",
       "8                100               5                0.05   \n",
       "5                500               5               0.005   \n",
       "0                200               6                0.05   \n",
       "9                300               2                 0.1   \n",
       "1                300               5                0.05   \n",
       "2                500               2                0.05   \n",
       "6                500               2                0.01   \n",
       "3                200               3                 0.5   \n",
       "7                500               4               0.001   \n",
       "4                100               2               0.005   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "8  {'n_estimators': 100, 'max_depth': 5, 'learnin...           0.731154   \n",
       "5  {'n_estimators': 500, 'max_depth': 5, 'learnin...           0.760083   \n",
       "0  {'n_estimators': 200, 'max_depth': 6, 'learnin...           0.630181   \n",
       "9  {'n_estimators': 300, 'max_depth': 2, 'learnin...           0.642003   \n",
       "1  {'n_estimators': 300, 'max_depth': 5, 'learnin...           0.597079   \n",
       "2  {'n_estimators': 500, 'max_depth': 2, 'learnin...           0.650209   \n",
       "6  {'n_estimators': 500, 'max_depth': 2, 'learnin...           0.758554   \n",
       "3  {'n_estimators': 200, 'max_depth': 3, 'learnin...           0.527816   \n",
       "7  {'n_estimators': 500, 'max_depth': 4, 'learnin...           0.751599   \n",
       "4  {'n_estimators': 100, 'max_depth': 2, 'learnin...           0.739638   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "8           0.859388           0.865090         0.818544        0.061838   \n",
       "5           0.838248           0.843115         0.813815        0.038046   \n",
       "0           0.886092           0.895132         0.803802        0.122824   \n",
       "9           0.869263           0.876634         0.795967        0.108910   \n",
       "1           0.889708           0.894854         0.793880        0.139175   \n",
       "2           0.857858           0.868150         0.792072        0.100401   \n",
       "6           0.784979           0.797914         0.780482        0.016380   \n",
       "3           0.899444           0.908067         0.778442        0.177254   \n",
       "7           0.769680           0.787900         0.769726        0.014820   \n",
       "4           0.741586           0.753129         0.744784        0.005954   \n",
       "\n",
       "   rank_test_score  \n",
       "8                1  \n",
       "5                2  \n",
       "0                3  \n",
       "9                4  \n",
       "1                5  \n",
       "2                6  \n",
       "6                7  \n",
       "3                8  \n",
       "7                9  \n",
       "4               10  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(random_xgb_poly_ovsp.cv_results_).sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy : 0.8461288827074641\n",
      "validation accuracy : 0.7870563674321504\n"
     ]
    }
   ],
   "source": [
    "pred_train_poly_ovsp = random_xgb_poly_ovsp.predict(X_train_poly_ovsp)\n",
    "pred_val_poly_ovsp = random_xgb_poly_ovsp.predict(X_val_poly)\n",
    "\n",
    "print('train accuracy :', accuracy_score(y_train_poly_ovsp, pred_train_poly_ovsp))\n",
    "print('validation accuracy :', accuracy_score(y_val, pred_val_poly_ovsp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
